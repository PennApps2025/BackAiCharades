# vlm.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from PIL import Image
import io

# --- Setup ---
load_dotenv()

# API í‚¤ ë™ì  ë¡œë“œ (GEMINI_API_KEY, GEMINI_API_KEY_2, GEMINI_API_KEY_3, ...)
API_KEYS = []
key_index = 1
while True:
    if key_index == 1:
        key = os.getenv("GEMINI_API_KEY")
    else:
        key = os.getenv(f"GEMINI_API_KEY_{key_index}")
    
    if key:
        API_KEYS.append(key)
        print(f"âœ… Loaded API Key #{key_index}")
        key_index += 1
    else:
        break  # No more keys found

if not API_KEYS:
    raise ValueError("No GEMINI_API_KEY found in .env file. Add at least GEMINI_API_KEY=your_key")

print(f"ğŸ“Š Total API Keys loaded: {len(API_KEYS)}")

# ëª¨ë¸ ìš°ì„ ìˆœìœ„ (ë¬´ë£Œ í”Œëœ ë¹„ì „ ëª¨ë¸)
# 
# ì‹œìŠ¤í…œ ì„¤ì •: 10ì´ˆ ìº¡ì²˜ ê°„ê²© = 6 calls/min
# ê²Œì„ë‹¹ ì˜ˆìƒ: 4-5íšŒ API í˜¸ì¶œ (45ì´ˆ ê²Œì„)
# 
# ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ì „ ëª¨ë¸:
# â€¢ gemini-2.5-flash-lite: 10 RPM, 20 RPD - ë¹ ë¦„ (300-800ms)
# â€¢ gemini-2.5-flash: 5 RPM, 20 RPD
# 
# ì „ëµ: ëª¨ë¸ ìš°ì„  ìˆœíšŒ
# 1. ëª¨ë“  í‚¤ì—ì„œ flash-lite ì‹œë„ (Key#1, #2, #3)
# 2. ëª¨ë“  flash-lite ì†Œì§„ ì‹œ flash ì‹œë„ (Key#1, #2, #3)
# 
# 3ê°œ API í‚¤ Ã— 2ê°œ ëª¨ë¸ Ã— 20 RPD = 120 calls/day (í•˜ë£¨ 24ê²Œì„)
MODEL_PRIORITY = [
    "gemini-2.5-flash-lite",  # ëª¨ë“  í‚¤ì—ì„œ ë¨¼ì € ì‹œë„
#     "gemini-2.5-flash",       # flash-lite ì†Œì§„ í›„ ì‚¬ìš©
#     "gemini-robotics-er-1.5-preview"
]

# ë§ˆì§€ë§‰ ì„±ê³µí•œ ì¡°í•© ê¸°ì–µ (ìŠ¤ë§ˆíŠ¸ ë¡œí…Œì´ì…˜)
# ì´ˆê¸°ê°’: Noneìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ì²« ì„±ê³µ ì‹œ í•™ìŠµ
last_successful_key_index = None
last_successful_model = None
# -------------

def generate_prompt(word_to_guess: str, choices: list) -> str:
    """Creates a high-quality prompt for the VLM to improve accuracy."""
    # Shuffle the choices to ensure the correct word isn't always in the same spot
    import random
    random.shuffle(choices)
    
    return f"""
You are an AI playing charades. Based on the image provided, pick the word from the list that best matches
the action the person is acting out. Only pick a word if you are more than 40% confident. 
If you pick a word, also explain in 1 short sentence why you chose it. 
If none of the words seem like a reasonable match, respond with a short "not sure" style message. 
Make it playful and casual. 
Do not use Markdown formatting. Your response should be plain text only.  

Choices: {', '.join(choices)}
"""

def vlm_guess(image_bytes: bytes, mime_type: str, word: str, all_choices: list) -> str:
    """
    Calls the Gemini API with smart rotation (remembers last successful combination).
    Tries last successful combo first, then falls back to sequential search.
    """
    global last_successful_key_index, last_successful_model
    
    # Generate prompt
    prompt = generate_prompt(word, all_choices)
    
    # ë§ˆì§€ë§‰ ì„±ê³µ ì¡°í•©ì´ ìˆìœ¼ë©´ ë¨¼ì € ì‹œë„ (ìŠ¤ë§ˆíŠ¸ ë¡œí…Œì´ì…˜)
    if last_successful_key_index is not None and last_successful_model is not None:
        try:
            key_index = last_successful_key_index
            model_name = last_successful_model
            api_key = API_KEYS[key_index - 1]
            
            print(f"ğŸ¯ Smart retry: Key#{key_index} + {model_name}")
            
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(model_name)
            image = Image.open(io.BytesIO(image_bytes))
            response = model.generate_content([prompt, image])
            
            # ì„±ê³µí•œ ì¡°í•© ê¸°ì–µ
            last_successful_key_index = key_index
            last_successful_model = model_name
            
            print(f"âœ… Success: Key#{key_index} + {model_name}")
            print(f"Original response: {response.text}")
            return response.text
            
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ Last combo failed: {error_msg[:100]}")
            print("âš ï¸ Switching to next available combo...")
    
    # ëª¨ë“  API í‚¤ì™€ ëª¨ë¸ ì¡°í•© ì‹œë„ (ëª¨ë¸ ìš°ì„  ìˆœíšŒ)
    for model_name in MODEL_PRIORITY:
        for key_index, api_key in enumerate(API_KEYS, 1):
            try:
                print(f"Trying: Key#{key_index} + {model_name}")
                
                # Configure API with current key
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel(model_name)
                
                # Prepare image
                image = Image.open(io.BytesIO(image_bytes))
                
                # Make API call
                response = model.generate_content([prompt, image])
                
                # ì„±ê³µí•œ ì¡°í•© ê¸°ì–µ
                last_successful_key_index = key_index
                last_successful_model = model_name
                
                print(f"âœ… Success: Key#{key_index} + {model_name}")
                print(f"Original response: {response.text}")
                return response.text
                
            except Exception as e:
                error_msg = str(e)
                print(f"âŒ Key#{key_index} + {model_name}: {error_msg[:100]}")
                
                # Check if it's a quota error
                if "quota" in error_msg.lower() or "429" in error_msg:
                    print("âš ï¸ Quota exceeded, trying next...")
                    continue
                else:
                    print("âš ï¸ Other error, trying next...")
                    continue
    
    # All attempts failed
    print("âŒ All API keys and models exhausted")
    return "quota_exceeded"